{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "MODELS = {\n",
    "    \"gpt\": \"gpt-4o\",\n",
    "    \"claude\": \"claude-3-5-sonnet-202401022\",\n",
    "    \"mixtral\": \"mixtral:8x7b\",\n",
    "    \"llama2\": \"llama2\",\n",
    "    \"llama3\": \"llama3.3\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhy don't scientists trust atoms? Because they make up everything! ğŸ˜‚\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "exec_model = \"llama2\"\n",
    "if exec_model == \"gpt\":\n",
    "    model = ChatOpenAI(api_key=OPENAI_API_KEY, model=MODELS[\"gpt\"])\n",
    "elif exec_model == \"anthropic\":\n",
    "    model = ChatAnthropic(api_key=ANTHROPIC_API_KEY, model=MODELS[\"anthropic\"])\n",
    "else:\n",
    "    model = OllamaLLM(model=MODELS[\"llama2\"])\n",
    "\n",
    "model.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sure! Here's a classic one:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "Because they make up everything!\n",
      "\n",
      "I hope that brought a smile to your face!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser\n",
    "\n",
    "print(chain.invoke(\"Tell me a joke\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='â—„ â–² â–º \\nA A A\\n#6 Probability (10/13/61)\\nThe recording of this lecture is missing\\nfrom the Caltech Archives.\\n6\\nProbability\\n(There was no summary for this lecture.)\\n(There was no summary for this lecture.)\\nâ€œThe true logic of this world is in the calculus of probabilities.â€   â€”James\\xa0Clerk\\xa0Maxwell\\n6â€“1Chance and likelihood\\nâ€œChanceâ€ is a word which is in common use in everyday living. The radio reportsspeaking of tomorrowâ€™s weather may say: â€œThere is a sixty percent chance of rain.â€ Youmight say: â€œThere is a small chance that I shall live to be one hundred years old.â€Scientists also use the word chance. A seismologist may be interested in the question:â€œWhat is the chance that there will be an earthquake of a certain size in SouthernCalifornia next year?â€ A physicist might ask the question: â€œWhat is the chance that aparticular geiger counter will register twenty counts in the next ten seconds?â€ A politicianor statesman might be interested in the question: â€œWhat is the chance that there will be anuclear war within the next ten years?â€ You may be interested in the chance that you willlearn something from this chapter.\\n00:02 1x 58:27\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 1/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='By chance, we mean something like a guess. Why do we make guesses? We makeguesses when we wish to make a judgment but have incomplete information or uncertainknowledge. We want to make a guess as to what things are, or what things are likely tohappen. Often we wish to make a guess because we have to make a decision. Forexample: Shall I take my raincoat with me tomorrow? For what earth movement should Idesign a new building? Shall I build myself a fallout shelter? Shall I change my stand ininternational negotiations? Shall I go to class today?\\nSometimes we make guesses because we wish, with our limited knowledge, to say asmuch as we can about some situation. Really, any generalization is in the nature of aguess. Any physical theory is a kind of guesswork. There are good guesses and there arebad guesses. The theory of probability is a system for making better guesses. Thelanguage of probability allows us to speak quantitatively about some situation which maybe highly variable, but which does have some consistent average behavior.\\nLet us consider the ï¬‚ipping of a coin. If the tossâ€”and the coinâ€”are â€œhonest,â€ we haveno way of knowing what to expect for the outcome of any particular toss. Yet we wouldfeel that in a large number of tosses there should be about equal numbers of heads andtails. We say: â€œThe probability that a toss will land heads is\\xa0.â€\\nWe speak of probability only for observations that we contemplate being made in thefuture. By the â€œprobabilityâ€ of a particular outcome of an observation we mean ourestimate for the most likely fraction of a number of repeated observations that will yieldthat particular outcome. If we imagine repeating an observationâ€”such as looking at afreshly tossed coinâ€”\\xa0times, and if we call  our estimate of the most likely numberof our observations that will give some speciï¬ed result\\xa0, say the result â€œheads,â€ then by\\xa0, the probability of observing\\xa0, we mean\\nOur deï¬nition requires several comments. First of all, we may speak of a probability ofsomething happening only if the occurrence is a possible outcome of some repeatableobservation. It is not clear that it would make any sense to ask: â€œWhat is the probabilitythat there is a ghost in that house?â€\\nYou may object that no situation is exactly repeatable. That is right. Every differentobservation must at least be at a different time or place. All we can say is that theâ€œrepeatedâ€ observations should, for our intended purposes, appear to be equivalent. Weshould assume, at least, that each observation was made from an equivalently preparedsituation, and especially with the same degree of ignorance at the start. (If we sneak alook at an opponentâ€™s hand in a card game, our estimate of our chances of winning aredifferent than if we do not!)\\nWe should emphasize that  and\\xa0  in Eq.\\xa0(6.1) are not intended to represent numbersbased on actual observations.  is our best estimate of what would occur in\\xa0imagined observations. Probability depends, therefore, on our knowledge and on ourability to make estimates. In effect, on our common sense! Fortunately, there is a certainamount of agreement in the common sense of many things, so that different people willmake the same estimate. Probabilities need not, however, be â€œabsoluteâ€ numbers. Sincethey depend on our ignorance, they may become different if our knowledge changes.\\nYou may have noticed another rather â€œsubjectiveâ€ aspect of our deï¬nition of probability.We have referred to\\xa0 as â€œour estimate of the most likely number â€¦â€ We do not meanthat we expect to observe exactly\\xa0 , but that we expect a number near\\xa0 , and that thenumber\\xa0 is more likely than any other number in the vicinity. If we toss a coin, say,\\xa0times, we should expect that the number of heads would not be very likely to beexactly\\xa0, but rather only some number near to\\xa0, say ,\\xa0 , , , , or\\xa0.However, if we must choose, we would decide that \\xa0heads is more likely than any othernumber. We would write\\xa0 .'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='Why did we choose\\xa0 as more likely than any other number? We must have argued withourselves in the following manner: If the most likely number of heads is\\xa0 in a totalnumber of tosses\\xa0, then the most likely number of tails\\xa0 is\\xa0 . (We areassuming that every toss gives either heads or tails, and no â€œotherâ€ result!) But if the coinis â€œhonest,â€ there is no preference for heads or tails. Until we have some reason to thinkthe coin (or toss) is dishonest, we must give equal likelihoods for heads and tails. So wemust set\\xa0 . It follows that\\xa0  , or\\xa0   .\\n0.5\\nN NA AP(A) A\\nP(A)= /N.NA (6.1)\\nN NANA N\\nNA NA NANA30 15 15 1213141516 1715P(heads)=0.5\\n15 NHN NT (Nâˆ’ )NH\\n=NT NH =NT =NH N/2 P(H)=P(T)=0.5\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 2/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='We can generalize our reasoning to any situation in which there are \\xa0different butâ€œequivalentâ€ (that is, equally likely) possible results of an observation. If an observationcan yield \\xa0different results, and we have reason to believe that any one of them is aslikely as any other, then the probability of a particular outcome  is\\xa0 .\\nIf there are seven different-colored balls in an opaque box and we pick one out â€œatrandomâ€ (that is, without looking), the probability of getting a ball of a particular color is. The probability that a â€œblind drawâ€ from a shufï¬‚ed deck of  cards will show the ten\\nof hearts is . The probability of throwing a double-one with dice is .\\nIn Chapter\\xa05 we described the size of a nucleus in terms of its apparent area, or â€œcrosssection.â€ When we did so we were really talking about probabilities. When we shoot ahigh-energy particle at a thin slab of material, there is some chance that it will pass rightthrough and some chance that it will hit a nucleus. (Since the nucleus is so small that wecannot see it, we cannot aim right at a nucleus. We must â€œshoot blind.â€) If there are\\xa0atoms in our slab and the nucleus of each atom has a cross-sectional area\\xa0, then thetotal area â€œshadowedâ€ by the nuclei is\\xa0. In a large number\\xa0 of random shots, weexpect that the number of hits\\xa0 of some nucleus will be in the ratio to\\xa0 as theshadowed area is to the total area of the slab:\\nWe may say, therefore, that the probability that any one projectile particle will suffer acollision in passing through the slab is\\nwhere  is the number of atoms per unit area in our slab.\\n6â€“2Fluctuations\\nFig. 6â€“1.Observed sequences of heads and tails in three games of 30\\xa0tosses each.\\nWe would like now to use our ideas about probability to consider in some greater detailthe question: â€œHow many heads do I really expect to get if I toss a coin \\xa0times?â€ Beforeanswering the question, however, let us look at what does happen in such anâ€œexperiment.â€ Figure\\xa06â€“1 shows the results obtained in the ï¬rst three â€œrunsâ€ of such anexperiment in which\\xa0. The sequences of â€œheadsâ€ and â€œtailsâ€ are shown just asthey were obtained. The ï¬rst game gave \\xa0heads; the second also\\xa0; the third\\xa0. Inthree trials we did not once get \\xa0heads. Should we begin to suspect the coin? Or werewe wrong in thinking that the most likely number of â€œheadsâ€ in such a game is\\xa0?Ninety-seven more runs were made to obtain a total of \\xa0experiments of \\xa0tosses\\neach. The results of the experiments are given in Table\\xa06â€“1.1\\nm\\nm A P(A)=1/m\\n17 52\\n152 136\\nn ÏƒnÏƒ NNC N\\n/N=nÏƒ/A.NC (6.2)\\n= Ïƒ,PC n\\nA (6.3)\\nn/A\\nN\\nN=30 11 11 1615 15100 30\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 3/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='Table 6â€“1Number of heads insuccessive trials of 30\\xa0tosses of acoin.\\nLooking at the numbers in Table\\xa06â€“1, we see that most of the results are â€œnearâ€\\xa0, in thatthey are between  and\\xa0. We can get a better feeling for the details of these results ifwe plot a graph of the distribution of the results. We count the number of games in whicha score of\\xa0 was obtained, and plot this number for each\\xa0. Such a graph is shown inFig.\\xa06â€“2. A score of \\xa0heads was obtained in \\xa0games. A score of \\xa0heads was alsoobtained \\xa0times. Scores of  and\\xa0 were each obtained more than \\xa0times. Are weto conclude that there is some bias toward heads? Was our â€œbest estimateâ€ not goodenough? Should we conclude now that the â€œmost likelyâ€ score for a run of \\xa0tosses isreally \\xa0heads? But wait! In all the games taken together, there were \\xa0tosses. Andthe total number of heads obtained was\\xa0. The fraction of tosses that gave heads is\\xa0, very nearly, but slightly less than half. We should certainly not assume that theprobability of throwing heads is greater than\\xa0! The fact that one particular set ofobservations gave \\xa0heads most often, is a ï¬‚uctuation. We still expect that the mostlikely number of heads is\\xa0.\\nFig. 6â€“2.Summary of the results of 100\\xa0games of 30\\xa0tosses each. The vertical bars showthe number of games in which a score of \\xa0heads was obtained. The dashed curve showsthe expected numbers of games with the score\\xa0 obtained by a probability computation.\\nWe may ask the question: â€œWhat is the probability that a game of \\xa0tosses will yield\\xa0headsâ€”or\\xa0, or any other number?â€ We have said that in a game of one toss, theprobability of obtaining one head is\\xa0, and the probability of obtaining no head is\\xa0.In a game of two tosses there are four possible outcomes: ,\\xa0 , ,\\xa0 . Sinceeach of these sequences is equally likely, we conclude that (a)\\xa0the probability of a scoreof two heads is\\xa0, (b)\\xa0the probability of a score of one head is\\xa0, (c)\\xa0the probability of a\\nzero score is\\xa0. There are two ways of obtaining one head, but only one of obtaining\\neither zero or two heads.\\n11161715171619181513\\n100\\xa0trials\\n11171712202311161714\\n16121510181713151415\\n16121122122012151612\\n16101513141615161318\\n14141316151921141215\\n16111614171411161716\\n19151412181514211116\\n171712131417 9131913\\n14121517141017171211\\n1512 18\\nk k15 13 1413 16 17 13\\n3016 300014930.498 0.516 15\\nk k\\n3015 16 0.5 0.5HHHTTHTT\\n14 2414\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 4/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='Consider now a game of \\xa0tosses. The third toss is equally likely to be heads or tails.There is only one way to obtain \\xa0heads: we must have obtained \\xa0heads on the ï¬rst twotosses, and then heads on the last. There are, however, three ways of obtaining \\xa0heads.We could throw tails after having thrown two heads (one way) or we could throw headsafter throwing only one head in the ï¬rst two tosses (two ways). So for scores of - ,\\xa0 -, - ,\\xa0 -  we have that the number of equally likely ways is ,\\xa0 , ,\\xa0 , with a total of\\xa0different possible sequences. The probabilities are , , , .\\nFig. 6â€“3.A diagram for showing the number of ways a score of 0,\\xa01, 2, or\\xa03 heads can beobtained in a game of 3\\xa0tosses.\\nFig. 6â€“4.A diagram like that of Fig.\\xa06â€“3, for a game of 6\\xa0tosses.\\nThe argument we have been making can be summarized by a diagram like that in Fig.\\xa06â€“3. It is clear how the diagram should be continued for games with a larger number oftosses. Figure\\xa06â€“4 shows such a diagram for a game of \\xa0tosses. The number of â€œwaysâ€ toany point on the diagram is just the number of different â€œpathsâ€ (sequences of heads andtails) which can be taken from the starting point. The vertical position gives us the totalnumber of heads thrown. The set of numbers which appears in such a diagram is knownas Pascalâ€™s triangle. The numbers are also known as the binomial coefï¬cients, becausethey also appear in the expansion of\\xa0. If we call  the number of tosses and the number of heads thrown, then the numbers in the diagram are usually designated bythe symbol\\xa0. We may remark in passing that the binomial coefï¬cients can also be\\ncomputed from\\nwhere , called â€œ-factorial,â€ represents the product\\xa0 .\\nWe are now ready to compute the probability\\xa0 of throwing \\xa0heads in \\xa0tosses,using our deï¬nition Eq.\\xa0(6.1). The total number of possible sequences is\\xa0 (since thereare \\xa0outcomes for each toss), and the number of ways of obtaining \\xa0heads is\\xa0, all\\nequally likely, so we have\\n3 3 2 2\\n3H2H1H0H 13318 18 38 38 18\\n6\\n(a+b)n n k\\n()nk\\n()= ,n\\nk\\nn!\\nk!(nâˆ’k)! (6.4)\\nn! n (n)(nâˆ’1)(nâˆ’2)â‹¯(3)(2)(1)\\nP(k,n) k n2n\\n2 k ()nk\\nP(k,n)= .()nk\\n2n (6.5)\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 5/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='Since  is the fraction of games which we expect to yield \\xa0heads, then in\\xa0games we should expect to ï¬nd \\xa0heads \\xa0times. The dashed curve inFig.\\xa06â€“2 passes through the points computed from\\xa0. We see that we expectto obtain a score of \\xa0heads in  or \\xa0games, whereas this score was observed in\\xa0games. We expect a score of\\xa0 in  or \\xa0games, but we obtained that score in\\xa0games. Such ï¬‚uctuations are â€œpart of the game.â€\\nThe method we have just used can be applied to the most general situation in which thereare only two possible outcomes of a single observation. Let us designate the twooutcomes by\\xa0 (for â€œwinâ€) and\\xa0 (for â€œloseâ€). In the general case, the probability of or\\xa0 in a single event need not be equal. Let  be the probability of obtaining the result\\xa0. Then , the probability of\\xa0, is necessarily\\xa0. In a set of \\xa0trials, theprobability\\xa0  that  will be obtained \\xa0times is\\nThis probability function is called the Bernoulli or, also, the binomial probability.\\n6â€“3The random walk\\nThere is another interesting problem in which the idea of probability is required. It is theproblem of the â€œrandom walk.â€ In its simplest version, we imagine a â€œgameâ€ in which aâ€œplayerâ€ starts at the point\\xa0 and at each â€œmoveâ€ is required to take a step eitherforward (toward\\xa0) or backward (toward\\xa0). The choice is to be made randomly,determined, for example, by the toss of a coin. How shall we describe the resultingmotion? In its general form the problem is related to the motion of atoms (or otherparticles) in a gasâ€”called Brownian motionâ€”and also to the combination of errors inmeasurements. You will see that the random-walk problem is closely related to the coin-tossing problem we have already discussed.\\nFirst, let us look at a few examples of a random walk. We may characterize the walkerâ€™sprogress by the net distance\\xa0 traveled in \\xa0steps. We show in the graph of Fig.\\xa06â€“5three examples of the path of a random walker. (We have used for the random sequenceof choices the results of the coin tosses shown in Fig.\\xa06â€“1.)\\nFig. 6â€“5.The progress made in a random walk. The horizontal coordinate\\xa0 is the totalnumber of steps taken; the vertical coordinate\\xa0 is the net distance moved from thestarting position.\\nWhat can we say about such a motion? We might ï¬rst ask: â€œHow far does he get on theaverage?â€ We must expect that his average progress will be zero, since he is equallylikely to go either forward or backward. But we have the feeling that as\\xa0 increases, heis more likely to have strayed farther from the starting point. We might, therefore, askwhat is his average distance travelled in absolute value, that is, what is the average of\\xa0. It is, however, more convenient to deal with another measure of â€œprogress,â€ the\\nP(k,n) k100 k 100â‹…P(k,n)100â‹…P(k,30)15 14 1513 16 13 1415\\nW L WL pW q L (1âˆ’p) nP(k,n) W k\\nP(k,n)=() .nkpkqnâˆ’k (6.6)\\nx=0+x âˆ’x\\nDN N\\nNDN\\nN\\n|D|\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 6/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='square of the distance:  is positive for either positive or negative motion, and istherefore a reasonable measure of such random wandering.\\nWe can show that the expected value of\\xa0 is just\\xa0, the number of steps taken. Byâ€œexpected valueâ€ we mean the probable value (our best guess), which we can think of asthe expected average behavior in many repeated sequences. We represent such anexpected value by\\xa0, and may refer to it also as the â€œmean square distance.â€ After\\none step,  is always\\xa0, so we have certainly\\xa0. (All distances will bemeasured in terms of a unit of one step. We shall not continue to write the units ofdistance.)\\nThe expected value of\\xa0 for\\xa0  can be obtained from\\xa0. If, after\\xa0steps, we have , then after \\xa0steps we have  or\\xa0. For the squares,\\nIn a number of independent sequences, we expect to obtain each value one-half of thetime, so our average expectation is just the average of the two possible values. Theexpected value of\\xa0 is then . In general, we should expect for\\xa0  its\\nâ€œexpected valueâ€\\xa0 (by deï¬nition!). So\\nWe have already shown that\\xa0; it follows then that\\na particularly simple result!\\nIf we wish a number like a distance, rather than a distance squared, to represent theâ€œprogress made away from the originâ€ in a random walk, we can use the â€œroot-mean-square distanceâ€\\xa0:\\nWe have pointed out that the random walk is closely similar in its mathematics to thecoin-tossing game we considered at the beginning of the chapter. If we imagine thedirection of each step to be in correspondence with the appearance of heads or tails in acoin toss, then  is just\\xa0 , the difference in the number of heads and tails. Since, the total number of steps (and tosses), we have . Wehave derived earlier an expression for the expected distribution of\\xa0 (also called\\xa0) andobtained the result of Eq.\\xa0(6.5). Since  is just a constant, we have the correspondingdistribution for\\xa0. (Since for every head more than  there is a tail â€œmissing,â€ wehave the factor of\\xa0 between  and\\xa0.) The graph of Fig.\\xa06â€“2 represents thedistribution of distances we might get in \\xa0random steps (where  is to be read; , ; etc.).\\nThe variation of  from its expected value  is\\nThe rms deviation is\\nAccording to our result for , we expect that the â€œtypicalâ€ distance in \\xa0steps oughtto be\\xa0 , or a typical\\xa0 should be about \\xa0units from\\xa0. We see\\nD2\\nD2N N\\nâŸ¨ âŸ©D2N\\nD2 +1 âŸ¨ âŸ©=1D21\\nD2N N>1 DNâˆ’1\\n(Nâˆ’1) DNâˆ’1 N = +1DN DNâˆ’1= âˆ’1DN DNâˆ’1\\n=D2N\\nâ§\\nâ©\\nâ¨\\nâªâªâªâª\\nâªâªâªâª\\n+2 +1,D2Nâˆ’1 DNâˆ’1\\nor\\nâˆ’2 +1.D2Nâˆ’1 DNâˆ’1\\n(6.7)\\nD2N +1D2Nâˆ’1 D2Nâˆ’1\\nâŸ¨ âŸ©D2Nâˆ’1\\nâŸ¨ âŸ©=âŸ¨ âŸ©+1.D2N D2Nâˆ’1 (6.8)\\nâŸ¨ âŸ©=1D21\\nâŸ¨ âŸ©=N,D2N (6.9)\\nDrms\\n= = .Drms âŸ¨ âŸ©D2âˆ’âˆ’âˆ’âˆ’âˆš Nâˆ’âˆ’âˆš (6.10)\\nD âˆ’NH NT+ =NNH NT D=2 âˆ’NNHNH kND N/22 NH D30 k=15D=0k=16D=2\\nNH N/2\\nâˆ’ = .NH N\\n2\\nD\\n2 (6.11)\\n( âˆ’ = .NH N\\n2)\\nrms\\n12 Nâˆ’âˆ’âˆš (6.12)\\nDrms 30â‰ˆ5.530âˆ’âˆ’âˆš k 5.5/2=2.75 15\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 7/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='that the â€œwidthâ€ of the curve in Fig.\\xa06â€“2, measured from the center, is just about \\xa0units,in agreement with this result.\\nWe are now in a position to consider a question we have avoided until now. How shall wetell whether a coin is â€œhonestâ€ or â€œloadedâ€? We can give now at least a partial answer. Foran honest coin, we expect the fraction of the times heads appears to be\\xa0, that is,\\nWe also expect an actual  to deviate from\\xa0 by about , or the fraction todeviate by\\nThe larger  is, the closer we expect the fraction\\xa0 to be to one-half.\\nFig. 6â€“6.The fraction of the tosses that gave heads in a particular sequence of \\xa0tosses ofa penny.\\nIn Fig.\\xa06â€“6 we have plotted the fraction\\xa0 for the coin tosses reported earlier in thischapter. We see the tendency for the fraction of heads to approach\\xa0 for large\\xa0.Unfortunately, for any given run or combination of runs there is no guarantee that theobserved deviation will be even near the expected deviation. There is always the ï¬nitechance that a large ï¬‚uctuationâ€”a long string of heads or tailsâ€”will give an arbitrarilylarge deviation. All we can say is that if the deviation is near the expected\\xa0 (saywithin a factor of  or\\xa0), we have no reason to suspect the honesty of the coin. If it ismuch larger, we may be suspicious, but cannot prove, that the coin is loaded (or that thetosser is clever!).\\nWe have also not considered how we should treat the case of a â€œcoinâ€ or some similarâ€œchancyâ€ object (say a stone that always lands in either of two positions) that we havegood reason to believe should have a different probability for heads and tails. We havedeï¬ned\\xa0 . How shall we know what to expect for\\xa0 ? In some cases,the best we can do is to observe the number of heads obtained in large numbers of tosses.For want of anything better, we must set\\xa0 . (How could weexpect anything else?) We must understand, however, that in such a case a differentexperiment, or a different observer, might conclude that  was different. We would\\nexpect, however, that the various answers should agree within the deviation\\xa0 [if is near one-half]. An experimental physicist usually says that an â€œexperimentallydeterminedâ€ probability has an â€œerror,â€ and writes\\nThere is an implication in such an expression that there is a â€œtrueâ€ or â€œcorrectâ€probability which could be computed if we knew enough, and that the observation maybe in â€œerrorâ€ due to a ï¬‚uctuation. There is, however, no way to make such thinkinglogically consistent. It is probably better to realize that the probability concept is in asense subjective, that it is always based on uncertain knowledge, and that its quantitativeevaluation is subject to change as we obtain more information.\\n6â€“4A probability distribution\\n3\\n0.5\\n=0.5.âŸ¨ âŸ©NH\\nN (6.13)\\nNH N/2 /2Nâˆ’âˆ’âˆš\\n= .1\\nN\\nNâˆ’âˆ’âˆš\\n2\\n1\\n2 Nâˆ’âˆ’âˆš\\nN /NNH\\nN\\n/NNH\\n0.5 N\\n1/2 Nâˆ’âˆ’âˆš2 3\\nP(H)=âŸ¨ âŸ©/NNH NH\\nâŸ¨ âŸ©= (observed)NH NH\\nP(H) 1/2 Nâˆ’âˆ’âˆšP(H)\\nP(H)= Â± .NH\\nN\\n1\\n2 Nâˆ’âˆ’âˆš (6.14)\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 8/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='Let us return now to the random walk and consider a modiï¬cation of it. Suppose that inaddition to a random choice of the direction (  or\\xa0) of each step, the length of each stepalso varied in some unpredictable way, the only condition being that on the average thestep length was one unit. This case is more representative of something like the thermalmotion of a molecule in a gas. If we call the length of a step\\xa0, then  may have anyvalue at all, but most often will be â€œnearâ€\\xa0. To be speciï¬c, we shall let\\xa0 or,equivalently, . Our derivation for\\xa0 would proceed as before except thatEq.\\xa0(6.8) would be changed now to read\\nWe have, as before, that\\nWhat would we expect now for the distribution of distances\\xa0? What is, for example, theprobability that  after \\xa0steps? The answer is zero! The probability is zero that will be any particular value, since there is no chance at all that the sum of the backwardsteps (of varying lengths) would exactly equal the sum of forward steps. We cannot plot agraph like that of Fig.\\xa06â€“2.\\nWe can, however, obtain a representation similar to that of Fig.\\xa06â€“2, if we ask, not what isthe probability of obtaining\\xa0 exactly equal to ,\\xa0 , or\\xa0, but instead what is theprobability of obtaining\\xa0 near ,\\xa0 , or\\xa0. Let us deï¬ne\\xa0  as the probability that will lie in the interval\\xa0 located at\\xa0 (say from  to\\xa0 ). We expect that forsmall\\xa0 the chance of\\xa0 landing in the interval is proportional to\\xa0, the width of theinterval. So we can write\\nThe function\\xa0 is called the probability density.\\nThe form of\\xa0 will depend on\\xa0, the number of steps taken, and also on thedistribution of individual step lengths. We cannot demonstrate the proofs here, but forlarge\\xa0,  is the same for all reasonable distributions in individual step lengths, anddepends only on\\xa0. We plot  for three values of\\xa0 in Fig.\\xa06â€“7. You will notice thatthe â€œhalf-widthsâ€ (typical spread from\\xa0) of these curves is\\xa0, as we have shownit should be.\\nFig. 6â€“7.The probability density for ending up at the distance\\xa0 from the starting placein a random walk of \\xa0steps. ( is measured in units of the rms step length.)\\nYou may notice also that the value of\\xa0 near zero is inversely proportional to\\xa0.This comes about because the curves are all of a similar shape and their areas under thecurves must all be equal. Since  is the probability of ï¬nding\\xa0 in\\xa0  when is small, we can determine the chance of ï¬nding\\xa0 somewhere inside an arbitrary intervalfrom  to\\xa0 , by cutting the interval in a number of small increments\\xa0 and evaluatingthe sum of the terms\\xa0 for each increment. The probability that  lands\\n+ âˆ’\\nS S1 âŸ¨ âŸ©=1S2\\n=1Srms âŸ¨ âŸ©D2\\nâŸ¨ âŸ©=âŸ¨ âŸ©+âŸ¨ âŸ©=âŸ¨ âŸ©+1.D2N D2Nâˆ’1 S2 D2Nâˆ’1 (6.15)\\nâŸ¨ âŸ©=N.D2N (6.16)\\nDD=0 30 D\\nD 01 2D 01 2 P(x,Î”x)D Î”x x x x+Î”xÎ”x D Î”x\\nP(x,Î”x)=p(x)Î”x. (6.17)\\np(x)\\np(x) N\\nNp(x) N p(x) Nx=0 Nâˆ’âˆ’âˆš\\nDN D\\np(x) Nâˆ’âˆ’âˆš\\np(x)Î”x D Î”x Î”xDx1 x2 Î”xp(x)Î”x D\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 9/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='somewhere between  and\\xa0, which we may write , is equal to theshaded area in Fig.\\xa06â€“8. The smaller we take the increments\\xa0, the more correct is ourresult. We can write, therefore,\\nFig. 6â€“8.The probability that the distance\\xa0 traveled in a random walk is between and\\xa0 is the area under the curve of\\xa0 from  to\\xa0 .\\nThe area under the whole curve is the probability that  lands somewhere (that is, hassome value between  and\\xa0 ). That probability is surely\\xa0. We must havethat\\nSince the curves in Fig.\\xa06â€“7 get wider in proportion to\\xa0, their heights must beproportional to\\xa0 to maintain the total area equal to\\xa0.\\nThe probability density function we have been describing is one that is encountered mostcommonly. It is known as the normal or Gaussian probability density. It has themathematical form\\nwhere  is called the standard deviation and is given, in our case, by\\xa0 or, if therms step size is different from\\xa0, by\\xa0 .\\nWe remarked earlier that the motion of a molecule, or of any particle, in a gas is like arandom walk. Suppose we open a bottle of an organic compound and let some of itsvapor escape into the air. If there are air currents, so that the air is circulating, the currentswill also carry the vapor with them. But even in perfectly still air, the vapor willgradually spread outâ€”will diffuseâ€”until it has penetrated throughout the room. Wemight detect it by its color or odor. The individual molecules of the organic vapor spreadout in still air because of the molecular motions caused by collisions with othermolecules. If we know the average â€œstepâ€ size, and the number of steps taken per second,we can ï¬nd the probability that one, or several, molecules will be found at some distancefrom their starting point after any particular passage of time. As time passes, more stepsare taken and the gas spreads out as in the successive curves of Fig.\\xa06â€“7. In a laterchapter, we shall ï¬nd out how the step sizes and step frequencies are related to thetemperature and pressure of a gas.\\nEarlier, we said that the pressure of a gas is due to the molecules bouncing against thewalls of the container. When we come later to make a more quantitative description, wewill wish to know how fast the molecules are going when they bounce, since the impactthey make will depend on that speed. We cannot, however, speak of the speed of themolecules. It is necessary to use a probability description. A molecule may have anyspeed, but some speeds are more likely than others. We describe what is going on bysaying that the probability that any particular molecule will have a speed between  and\\xa0 is , where\\xa0, a probability density, is a given function of the speed\\xa0.We shall see later how Maxwell, using common sense and the ideas of probability, was\\nx1 x2 P( <D< )x1 x2\\nÎ”x\\nP( <D< )=âˆ‘p(x)Î”xx1 x2\\n= p(x)dx.âˆ«\\nx2\\nx1\\n(6.18)\\nD x1x2 p(x) x1 x2\\nDx=âˆ’âˆ x=+âˆ 1\\np(x)dx=1.âˆ«\\n+âˆ\\nâˆ’âˆ (6.19)\\nNâˆ’âˆ’âˆš1/ Nâˆ’âˆ’âˆš 1\\np(x)= ,1\\nÏƒ 2Ï€âˆ’âˆ’âˆš eâˆ’ /2x2 Ïƒ2 (6.20)\\nÏƒ Ïƒ= Nâˆ’âˆ’âˆš1 Ïƒ= Nâˆ’âˆ’âˆš Srms\\nvv+Î”v p(v)Î”v p(v) v\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 10/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='able to ï¬nd a mathematical expression for\\xa0. The form2 of the function\\xa0 is shownin Fig.\\xa06â€“9. Velocities may have any value, but are most likely to be near the mostprobable value\\xa0.\\nFig. 6â€“9.The distribution of velocities of the molecules in a gas.\\nWe often think of the curve of Fig.\\xa06â€“9 in a somewhat different way. If we consider themolecules in a typical container (with a volume of, say, one liter), then there are a verylarge number\\xa0 of molecules present (). Since\\xa0  is the probability thatone molecule will have its velocity in\\xa0, by our deï¬nition of probability we mean thatthe expected number\\xa0  to be found with a velocity in the interval\\xa0 is given by\\nWe call  the â€œdistribution in velocity.â€ The area under the curve between twovelocities  and\\xa0, for example the shaded area in Fig.\\xa06â€“9, represents [for the curve\\xa0] the expected number of molecules with velocities between  and\\xa0. Since witha gas we are usually dealing with large numbers of molecules, we expect the deviationsfrom the expected numbers to be small (like\\xa0), so we often neglect to say theâ€œexpectedâ€ number, and say instead: â€œThe number of molecules with velocities between and\\xa0 is the area under the curve.â€ We should remember, however, that suchstatements are always about probable numbers.\\n6â€“5The uncertainty principle\\nThe ideas of probability are certainly useful in describing the behavior of the\\xa0 or somolecules in a sample of a gas, for it is clearly impractical even to attempt to write downthe position or velocity of each molecule. When probability was ï¬rst applied to suchproblems, it was considered to be a convenienceâ€”a way of dealing with very complexsituations. We now believe that the ideas of probability are essential to a description ofatomic happenings. According to quantum mechanics, the mathematical theory ofparticles, there is always some uncertainty in the speciï¬cation of positions and velocities.We can, at best, say that there is a certain probability that any particle will have a positionnear some coordinate\\xa0.\\nWe can give a probability density\\xa0, such that\\xa0  is the probability that theparticle will be found between  and\\xa0 . If the particle is reasonably well localized,say near\\xa0, the function\\xa0 might be given by the graph of Fig.\\xa06â€“10(a). Similarly,we must specify the velocity of the particle by means of a probability density\\xa0, with\\xa0 the probability that the velocity will be found between  and\\xa0 .\\np(v) p(v)\\nvp\\nN Nâ‰ˆ1022 p(v)Î”vÎ”vâŸ¨Î”NâŸ© Î”v\\nâŸ¨Î”NâŸ©=Np(v)Î”v. (6.21)\\nNp(v)v1 v2Np(v) v1 v2\\n1/ Nâˆ’âˆ’âˆš\\nv1 v2\\n1022\\nx\\n(x)p1 (x)Î”xp1\\nx x+Î”xx0 (x)p1\\n(v)p2\\n(v)Î”vp2 v v+Î”v\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 11/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='Fig. 6â€“10.Probability densities for observation of the position and velocity of a particle.\\nIt is one of the fundamental results of quantum mechanics that the two functions and\\xa0  cannot be chosen independently and, in particular, cannot both be madearbitrarily narrow. If we call the typical â€œwidthâ€ of the \\xa0curve , and that of the\\xa0curve  (as shown in the ï¬gure), nature demands that the product of the twowidths be at least as big as the number\\xa0, where  is the mass of the particle. Wemay write this basic relationship as\\nThis equation is a statement of the Heisenberg uncertainty principle that we mentionedearlier.\\nSince the right-hand side of Eq.\\xa0(6.22) is a constant, this equation says that if we try toâ€œpin downâ€ a particle by forcing it to be at a particular place, it ends up by having a highspeed. Or if we try to force it to go very slowly, or at a precise velocity, it â€œspreads outâ€so that we do not know very well just where it is. Particles behave in a funny way!\\nThe uncertainty principle describes an inherent fuzziness that must exist in any attempt todescribe nature. Our most precise description of nature must be in terms of probabilities.There are some people who do not like this way of describing nature. They feel somehowthat if they could only tell what is really going on with a particle, they could know itsspeed and position simultaneously. In the early days of the development of quantummechanics, Einstein was quite worried about this problem. He used to shake his head andsay, â€œBut, surely God does not throw dice in determining how electrons should go!â€ Heworried about that problem for a long time and he probably never really reconciledhimself to the fact that this is the best description of nature that one can give. There arestill one or two physicists who are working on the problem who have an intuitiveconviction that it is possible somehow to describe the world in a different way and that allof this uncertainty about the way things are can be removed. No one has yet beensuccessful.\\nThe necessary uncertainty in our speciï¬cation of the position of a particle becomes mostimportant when we wish to describe the structure of atoms. In the hydrogen atom, whichhas a nucleus of one proton with one electron outside of the nucleus, the uncertainty inthe position of the electron is as large as the atom itself! We cannot, therefore, properlyspeak of the electron moving in some â€œorbitâ€ around the proton. The most we can say isthat there is a certain chance\\xa0 , of observing the electron in an element ofvolume\\xa0 at the distance\\xa0 from the proton. The probability density\\xa0 is given by\\nquantum mechanics. For an undisturbed hydrogen atom . The number\\xa0is the â€œtypicalâ€ radius, where the function is decreasing rapidly. Since there is a smallprobability of ï¬nding the electron at distances from the nucleus much greater than\\xa0, wemay think of\\xa0 as â€œthe radius of the atom,â€ about \\xa0meter.\\n(x)p1\\n(v)p2\\n(x)p1 [Î”x](v)p2 [Î”v] â„/2m m\\n[Î”x]â‹…[Î”v]â‰¥â„/2m. (6.22)\\np(r)Î”VÎ”V r p(r)p(r)=Aeâˆ’2r/a a\\naa 10âˆ’10\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 12/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='Fig. 6â€“11.A way of visualizing a hydrogen atom. The density (whiteness) of the cloudrepresents the probability density for observing the electron.\\nWe can form an image of the hydrogen atom by imagining a â€œcloudâ€ whose density isproportional to the probability density for observing the electron. A sample of such acloud is shown in Fig.\\xa06â€“11. Thus our best â€œpictureâ€ of a hydrogen atom is a nucleussurrounded by an â€œelectron cloudâ€ (although we really mean a â€œprobability cloudâ€). Theelectron is there somewhere, but nature permits us to know only the chance of ï¬nding itat any particular place.\\nIn its efforts to learn as much as possible about nature, modern physics has found thatcertain things can never be â€œknownâ€ with certainty. Much of our knowledge must alwaysremain uncertain. The most we can know is in terms of probabilities.\\n1. After the ï¬rst three games, the experiment was actually done by shaking\\xa0pennies violently in a box and then counting the number of heads that showed.â†©\\n2. Maxwellâ€™s expression is , where  is a constant related to thetemperature and\\xa0 is chosen so that the total probability is one. â†©Copyright Â© 1963, 2006, 2013 by the California Institute of Technology, Michael A.Gottlieb and Rudolf Pfeiffer6â€“1Chance and likelihood6â€“2Fluctuations6â€“3The random walk6â€“4A probability distribution6â€“5The uncertainty principle\\n30\\np(v)=Cv2eâˆ’av2 aC\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 13/13')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"feynman.pdf\")\n",
    "\n",
    "pages = loader.load_and_split()\n",
    "pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to create a prompt template to ask the model questions from a specific context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you don't know the answer, just reply \"I don't know\".\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you don't know the answer, just reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to pass the prompt into the model via chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to pass in the context and question in order to invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sure! Based on the context you provided, your name is Brandon.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"context\": \"The name I was given was Brandon\",\n",
    "        \"question\": \"What is my name?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to know how to use the prompt we've created, we can use `input_schema.schema`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fh/pr28tpnx5v58ycdrr7lrcv1h0000gn/T/ipykernel_4483/3226659032.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  chain.input_schema.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'context': {'title': 'Context', 'type': 'string'},\n",
       "  'question': {'title': 'Question', 'type': 'string'}},\n",
       " 'required': ['context', 'question'],\n",
       " 'title': 'PromptInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to pass only the relevant parts of a pdf document as a context\n",
    "\n",
    "VectorStore to the rescue!\n",
    "\n",
    "1. Serves as a database for the content by generating embeddings for each page of the pdf so we can compare the embeddings to the question that the user is asking\n",
    "\n",
    "`uv add docarray`\n",
    "pydantic should already be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=MODELS[\"llama2\"]) # Since we're using Ollama, we need to use the OllamaEmbeddings class\n",
    "# Create a vector store in memory, ideally we would use something like pinecone or supabase\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    pages,\n",
    "    embedding=embeddings # Every model has its own way of creating embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning the `vectorstore` into a `retriever` which is a component of langchain which will allow you to retrieve information from anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='We can generalize our reasoning to any situation in which there are \\xa0different butâ€œequivalentâ€ (that is, equally likely) possible results of an observation. If an observationcan yield \\xa0different results, and we have reason to believe that any one of them is aslikely as any other, then the probability of a particular outcome  is\\xa0 .\\nIf there are seven different-colored balls in an opaque box and we pick one out â€œatrandomâ€ (that is, without looking), the probability of getting a ball of a particular color is. The probability that a â€œblind drawâ€ from a shufï¬‚ed deck of  cards will show the ten\\nof hearts is . The probability of throwing a double-one with dice is .\\nIn Chapter\\xa05 we described the size of a nucleus in terms of its apparent area, or â€œcrosssection.â€ When we did so we were really talking about probabilities. When we shoot ahigh-energy particle at a thin slab of material, there is some chance that it will pass rightthrough and some chance that it will hit a nucleus. (Since the nucleus is so small that wecannot see it, we cannot aim right at a nucleus. We must â€œshoot blind.â€) If there are\\xa0atoms in our slab and the nucleus of each atom has a cross-sectional area\\xa0, then thetotal area â€œshadowedâ€ by the nuclei is\\xa0. In a large number\\xa0 of random shots, weexpect that the number of hits\\xa0 of some nucleus will be in the ratio to\\xa0 as theshadowed area is to the total area of the slab:\\nWe may say, therefore, that the probability that any one projectile particle will suffer acollision in passing through the slab is\\nwhere  is the number of atoms per unit area in our slab.\\n6â€“2Fluctuations\\nFig. 6â€“1.Observed sequences of heads and tails in three games of 30\\xa0tosses each.\\nWe would like now to use our ideas about probability to consider in some greater detailthe question: â€œHow many heads do I really expect to get if I toss a coin \\xa0times?â€ Beforeanswering the question, however, let us look at what does happen in such anâ€œexperiment.â€ Figure\\xa06â€“1 shows the results obtained in the ï¬rst three â€œrunsâ€ of such anexperiment in which\\xa0. The sequences of â€œheadsâ€ and â€œtailsâ€ are shown just asthey were obtained. The ï¬rst game gave \\xa0heads; the second also\\xa0; the third\\xa0. Inthree trials we did not once get \\xa0heads. Should we begin to suspect the coin? Or werewe wrong in thinking that the most likely number of â€œheadsâ€ in such a game is\\xa0?Ninety-seven more runs were made to obtain a total of \\xa0experiments of \\xa0tosses\\neach. The results of the experiments are given in Table\\xa06â€“1.1\\nm\\nm A P(A)=1/m\\n17 52\\n152 136\\nn ÏƒnÏƒ NNC N\\n/N=nÏƒ/A.NC (6.2)\\n= Ïƒ,PC n\\nA (6.3)\\nn/A\\nN\\nN=30 11 11 1615 15100 30\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 3/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='somewhere between  and\\xa0, which we may write , is equal to theshaded area in Fig.\\xa06â€“8. The smaller we take the increments\\xa0, the more correct is ourresult. We can write, therefore,\\nFig. 6â€“8.The probability that the distance\\xa0 traveled in a random walk is between and\\xa0 is the area under the curve of\\xa0 from  to\\xa0 .\\nThe area under the whole curve is the probability that  lands somewhere (that is, hassome value between  and\\xa0 ). That probability is surely\\xa0. We must havethat\\nSince the curves in Fig.\\xa06â€“7 get wider in proportion to\\xa0, their heights must beproportional to\\xa0 to maintain the total area equal to\\xa0.\\nThe probability density function we have been describing is one that is encountered mostcommonly. It is known as the normal or Gaussian probability density. It has themathematical form\\nwhere  is called the standard deviation and is given, in our case, by\\xa0 or, if therms step size is different from\\xa0, by\\xa0 .\\nWe remarked earlier that the motion of a molecule, or of any particle, in a gas is like arandom walk. Suppose we open a bottle of an organic compound and let some of itsvapor escape into the air. If there are air currents, so that the air is circulating, the currentswill also carry the vapor with them. But even in perfectly still air, the vapor willgradually spread outâ€”will diffuseâ€”until it has penetrated throughout the room. Wemight detect it by its color or odor. The individual molecules of the organic vapor spreadout in still air because of the molecular motions caused by collisions with othermolecules. If we know the average â€œstepâ€ size, and the number of steps taken per second,we can ï¬nd the probability that one, or several, molecules will be found at some distancefrom their starting point after any particular passage of time. As time passes, more stepsare taken and the gas spreads out as in the successive curves of Fig.\\xa06â€“7. In a laterchapter, we shall ï¬nd out how the step sizes and step frequencies are related to thetemperature and pressure of a gas.\\nEarlier, we said that the pressure of a gas is due to the molecules bouncing against thewalls of the container. When we come later to make a more quantitative description, wewill wish to know how fast the molecules are going when they bounce, since the impactthey make will depend on that speed. We cannot, however, speak of the speed of themolecules. It is necessary to use a probability description. A molecule may have anyspeed, but some speeds are more likely than others. We describe what is going on bysaying that the probability that any particular molecule will have a speed between  and\\xa0 is , where\\xa0, a probability density, is a given function of the speed\\xa0.We shall see later how Maxwell, using common sense and the ideas of probability, was\\nx1 x2 P( <D< )x1 x2\\nÎ”x\\nP( <D< )=âˆ‘p(x)Î”xx1 x2\\n= p(x)dx.âˆ«\\nx2\\nx1\\n(6.18)\\nD x1x2 p(x) x1 x2\\nDx=âˆ’âˆ x=+âˆ 1\\np(x)dx=1.âˆ«\\n+âˆ\\nâˆ’âˆ (6.19)\\nNâˆ’âˆ’âˆš1/ Nâˆ’âˆ’âˆš 1\\np(x)= ,1\\nÏƒ 2Ï€âˆ’âˆ’âˆš eâˆ’ /2x2 Ïƒ2 (6.20)\\nÏƒ Ïƒ= Nâˆ’âˆ’âˆš1 Ïƒ= Nâˆ’âˆ’âˆš Srms\\nvv+Î”v p(v)Î”v p(v) v\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 10/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='able to ï¬nd a mathematical expression for\\xa0. The form2 of the function\\xa0 is shownin Fig.\\xa06â€“9. Velocities may have any value, but are most likely to be near the mostprobable value\\xa0.\\nFig. 6â€“9.The distribution of velocities of the molecules in a gas.\\nWe often think of the curve of Fig.\\xa06â€“9 in a somewhat different way. If we consider themolecules in a typical container (with a volume of, say, one liter), then there are a verylarge number\\xa0 of molecules present (). Since\\xa0  is the probability thatone molecule will have its velocity in\\xa0, by our deï¬nition of probability we mean thatthe expected number\\xa0  to be found with a velocity in the interval\\xa0 is given by\\nWe call  the â€œdistribution in velocity.â€ The area under the curve between twovelocities  and\\xa0, for example the shaded area in Fig.\\xa06â€“9, represents [for the curve\\xa0] the expected number of molecules with velocities between  and\\xa0. Since witha gas we are usually dealing with large numbers of molecules, we expect the deviationsfrom the expected numbers to be small (like\\xa0), so we often neglect to say theâ€œexpectedâ€ number, and say instead: â€œThe number of molecules with velocities between and\\xa0 is the area under the curve.â€ We should remember, however, that suchstatements are always about probable numbers.\\n6â€“5The uncertainty principle\\nThe ideas of probability are certainly useful in describing the behavior of the\\xa0 or somolecules in a sample of a gas, for it is clearly impractical even to attempt to write downthe position or velocity of each molecule. When probability was ï¬rst applied to suchproblems, it was considered to be a convenienceâ€”a way of dealing with very complexsituations. We now believe that the ideas of probability are essential to a description ofatomic happenings. According to quantum mechanics, the mathematical theory ofparticles, there is always some uncertainty in the speciï¬cation of positions and velocities.We can, at best, say that there is a certain probability that any particle will have a positionnear some coordinate\\xa0.\\nWe can give a probability density\\xa0, such that\\xa0  is the probability that theparticle will be found between  and\\xa0 . If the particle is reasonably well localized,say near\\xa0, the function\\xa0 might be given by the graph of Fig.\\xa06â€“10(a). Similarly,we must specify the velocity of the particle by means of a probability density\\xa0, with\\xa0 the probability that the velocity will be found between  and\\xa0 .\\np(v) p(v)\\nvp\\nN Nâ‰ˆ1022 p(v)Î”vÎ”vâŸ¨Î”NâŸ© Î”v\\nâŸ¨Î”NâŸ©=Np(v)Î”v. (6.21)\\nNp(v)v1 v2Np(v) v1 v2\\n1/ Nâˆ’âˆ’âˆš\\nv1 v2\\n1022\\nx\\n(x)p1 (x)Î”xp1\\nx x+Î”xx0 (x)p1\\n(v)p2\\n(v)Î”vp2 v v+Î”v\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 11/13'),\n",
       " Document(metadata={'producer': 'Skia/PDF m134', 'creator': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36', 'creationdate': '2025-03-29T18:58:41+00:00', 'title': 'The Feynman Lectures on Physics Vol. I Ch. 6: Probability', 'moddate': '2025-03-29T18:58:41+00:00', 'source': 'feynman.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='Fig. 6â€“10.Probability densities for observation of the position and velocity of a particle.\\nIt is one of the fundamental results of quantum mechanics that the two functions and\\xa0  cannot be chosen independently and, in particular, cannot both be madearbitrarily narrow. If we call the typical â€œwidthâ€ of the \\xa0curve , and that of the\\xa0curve  (as shown in the ï¬gure), nature demands that the product of the twowidths be at least as big as the number\\xa0, where  is the mass of the particle. Wemay write this basic relationship as\\nThis equation is a statement of the Heisenberg uncertainty principle that we mentionedearlier.\\nSince the right-hand side of Eq.\\xa0(6.22) is a constant, this equation says that if we try toâ€œpin downâ€ a particle by forcing it to be at a particular place, it ends up by having a highspeed. Or if we try to force it to go very slowly, or at a precise velocity, it â€œspreads outâ€so that we do not know very well just where it is. Particles behave in a funny way!\\nThe uncertainty principle describes an inherent fuzziness that must exist in any attempt todescribe nature. Our most precise description of nature must be in terms of probabilities.There are some people who do not like this way of describing nature. They feel somehowthat if they could only tell what is really going on with a particle, they could know itsspeed and position simultaneously. In the early days of the development of quantummechanics, Einstein was quite worried about this problem. He used to shake his head andsay, â€œBut, surely God does not throw dice in determining how electrons should go!â€ Heworried about that problem for a long time and he probably never really reconciledhimself to the fact that this is the best description of nature that one can give. There arestill one or two physicists who are working on the problem who have an intuitiveconviction that it is possible somehow to describe the world in a different way and that allof this uncertainty about the way things are can be removed. No one has yet beensuccessful.\\nThe necessary uncertainty in our speciï¬cation of the position of a particle becomes mostimportant when we wish to describe the structure of atoms. In the hydrogen atom, whichhas a nucleus of one proton with one electron outside of the nucleus, the uncertainty inthe position of the electron is as large as the atom itself! We cannot, therefore, properlyspeak of the electron moving in some â€œorbitâ€ around the proton. The most we can say isthat there is a certain chance\\xa0 , of observing the electron in an element ofvolume\\xa0 at the distance\\xa0 from the proton. The probability density\\xa0 is given by\\nquantum mechanics. For an undisturbed hydrogen atom . The number\\xa0is the â€œtypicalâ€ radius, where the function is decreasing rapidly. Since there is a smallprobability of ï¬nding the electron at distances from the nucleus much greater than\\xa0, wemay think of\\xa0 as â€œthe radius of the atom,â€ about \\xa0meter.\\n(x)p1\\n(v)p2\\n(x)p1 [Î”x](v)p2 [Î”v] â„/2m m\\n[Î”x]â‹…[Î”v]â‰¥â„/2m. (6.22)\\np(r)Î”VÎ”V r p(r)p(r)=Aeâˆ’2r/a a\\naa 10âˆ’10\\n3/29/25, 2:58 PM The Feynman Lectures on Physics Vol. I Ch. 6: Probability\\nhttps://www.feynmanlectures.caltech.edu/I_06.html 12/13')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.invoke(\"What did Feynman say about the second law of thermodynamics?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our chain. We need to provide a context and a question. \n",
    "The question is going to come from the retriever. \n",
    "\n",
    "The prompt is expecting a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Feynman.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "| prompt | model | parser )\n",
    "\n",
    "chain.invoke({\"question\": \"What's my name?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retriever requires a question\n",
    "`itemgetter` you can call a function with a dictionary and you get what you need which is a runnable\n",
    "Piping the question into a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Chapter 6 of \"The Feynman Lectures on Physics,\" Feynman discusses probability and its role in describing the behavior of particles at the quantum level. He presents several key points regarding probability in physics:\\n\\n1. Probability is a fundamental aspect of quantum mechanics, and it cannot be avoided or wished away.\\n2. The product of the widths of position and momentum probabilities must be greater than or equal to the number , which is the mass of the particle. This is known as the Heisenberg uncertainty principle.\\n3. In attempting to describe the world in a different way, some physicists still have an intuitive conviction that it is possible to remove all this uncertainty about the way things are. However, no one has been successful in doing so.\\n4. The necessary uncertainty in our specification of the position of a particle becomes most important when we wish to describe the structure of atoms. Specifically, there is a small probability of finding an electron at distances from the nucleus much greater than typical radius .\\n5. The product of the widths of position and momentum probabilities cannot be chosen independently; in other words, the product of the widths must be large enough to accommodate the number of the mass of the particle.\\n6. For an undisturbed hydrogen atom, the probability density function is given by .\\n7. The probability density function for a particle\\'s position and velocity can be represented graphically as a bell-shaped curve.\\n8. Quantum mechanics emphasizes that particles behave in a funny way; they cannot be described by precise positions or velocities. Instead, their behavior is described by probabilities.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    } \n",
    "    | prompt\n",
    "    | model \n",
    "    | parser\n",
    ")\n",
    "chain.invoke({\"question\": \"What did Feynman say about probability?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What did Feynman say about probability?\n",
      "Answer: Feynman said that in quantum mechanics, probabilities are the best way to describe nature, and that the uncertainty principle is a fundamental aspect of nature, stating that the product of the uncertainties in position and momentum is greater than or equal to h/2m, where h is Planck's constant and m is the mass of the particle. He also mentioned that particles behave in a funny way and that there are still some physicists who are working on removing this uncertainty, but no one has been successful yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"What did Feynman say about probability?\"\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {chain.invoke({'question': question})}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In chapter 6 of The Feynman Lectures on Physics, Richard Feynman discusses the concept of probability in physics. He explains that probability is a fundamental aspect of quantum mechanics and cannot be avoided. Feynman highlights several key points related to probability:\n",
      "\n",
      "1. Probability densities: Feynman shows how probability densities can be used to describe the position and velocity of particles. He uses figures to illustrate the shape of these probabilities.\n",
      "2. Uncertainty principle: Feynman explains that there is a fundamental uncertainty in our specification of the position of a particle, which becomes particularly important when describing the structure of atoms. He notes that the number represents the \"typical\" radius of the atom.\n",
      "3. Independence of widths: Feynman highlights that if we try to force particles to have a precise velocity or be in a particular place, nature demands that there must be some uncertainty involved. This means that we cannot choose independently how narrow these curves are.\n",
      "4. Heisenberg uncertainty principle: Feynman explicitly states the Heisenberg uncertainty principle, which is that the product of the uncertainties in position and momentum is greater than or equal to a certain constant (â„/2m).\n",
      "5. Probability of finding an electron at a distance from the nucleus: Feynman provides an example of how probability densities can be used to describe the location of an electron in an atom. He notes that there is a small probability of finding the electron at distances much greater than the typical radius of the atom.\n",
      "6. Funny way particles behave: Feynman states that there are still some physicists who work on removing this uncertainty, but no one has been successful. This highlights the idea that the uncertainty in position and momentum is an inherent aspect of quantum mechanics.\n",
      "\n",
      "In summary, Feynman emphasizes the importance of probability in quantum mechanics and how it affects our understanding of particle behavior. He shows how probability densities can be used to describe the position and velocity of particles, and how the uncertainty principle restricts how precisely we can determine these quantities."
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"question\": question}):\n",
    "    print(s, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feynman discussed the concept of probability in Chapter 6 of his \"Feynman Lectures on Physics.\" He explained that probability is a fundamental aspect of quantum mechanics, and that particles behave in a way that is inherently uncertain.\\n\\nFeynman noted that the position and velocity of a particle cannot be precisely known at the same time, due to the uncertainty principle. He also discussed how the necessary uncertainty in our specification of the position of a particle becomes most important when describing the structure of atoms.\\n\\nFeynman stated that particles behave in a \"funny way\" and that there is an inherent fuzziness in any attempt to describe nature. He also noted that some physicists still work on the problem of removing this uncertainty, but no one has been successful so far.\\n\\nOverall, Feynman emphasized the importance of probability in quantum mechanics and the limitations of precision in describing the behavior of particles at the atomic level.',\n",
       " 'In his lecture on probability, Feynman mentions the Heisenberg uncertainty principle, which implies that it is impossible to know both the position and momentum of a particle simultaneously with infinite precision. He also notes that this principle forms the basis of quantum mechanics and that particles behave in a \"funny way\" due to this uncertainty.\\n\\nRegarding the second law of thermodynamics, Feynman does not directly address it in his lecture on probability. The second law of thermodynamics states that the total entropy of a closed system cannot decrease over time, it can only stay the same or increase. Entropy is a measure of the amount of thermal energy unavailable to do work in a system.\\n\\nHowever, Feynman does touch on related topics in his lectures, such as the concept of probability and the limitations of classical physics when attempting to describe quantum phenomena. These topics are relevant to understanding the second law of thermodynamics, which is a fundamental principle in the field of thermodynamics.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"question\": \"What did Feynman say about probability?\"}, {\"question\": \"What did Feynman say about the second law of thermodynamics?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
